## 搜索引擎网页排序的思想算法

在信息检索中，每当用户检索一个短语，搜索引擎就将找出所有含有被检索短语的网页。(或许，类似“搜索”与“引擎”之间的距离这样的额外信息都被会考虑在内。)但问题是，我们现在需要检索几十亿甚至几百亿个页面，而这些页面上大约95%的文本仅由大约一万个单词组成。也就是说，对于大多数搜索而言，将会有超级多的网页含有搜索短语中的单词。我们所需要的其实是这样一种办法，它能够将这些符合搜索条件的网页按照重要度进行排序，这样才能够将最重要的页面排在最上面。

实际上，现在对于网页的排序是用它们的相关程度(relevance)和重要程度(importance)来作为指标来进行的。下面来介绍网页重要度的计算方法，也就是排序的算法。

### TF-IDF及其算法
在一份给定的文件里，词频 (term frequency, TF) 指的是某一个给定的词语在该文件中出现的次数。这个数字通常会被归一化（分子一般小于分母 区别于IDF），以防止它偏向长的文件。（同一个词语在长文件里可能会比短文件有更高的词频，而不管该词语重要与否.逆向文件频率 (inverse document frequency, IDF) 是一个词语普遍重要性的度量。某一特定词语的IDF，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到。(当然也有其他的计算方法，这种是使用比较广泛的思想)

TF-IDF的主要思想是：如果某个词或短语在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。TFIDF实际上是：TF * IDF，TF词频(Term Frequency)，IDF反文档频率(Inverse Document Frequency)。TF表示词条在文档d中出现的频率（另一说：TF词频(Term Frequency)指的是某一个给定的词语在该文件中出现的次数）。IDF的主要思想是：如果包含词条t的文档越少也就是n越小，IDF越大（见后续公式），则说明词条t具有很好的类别区分能力。如果某一类文档C中包含词条t的文档数为m，而其它类包含t的文档总数为k，显然所有包含t的文档数n=m+k，当m大的时候，n也大，按照IDF公式得到的IDF的值会小，就说明该词条t类别区分能力不强。（IDF反文档频率(Inverse Document Frequency)是指果包含词条的文档越少，IDF越大，则说明词条具有很好的类别区分能力。）但是实际上，有时候，如果一个词条在一个类的文档中频繁出现，则说明该词条能够很好代表这个类的文本的特征，这样的词条应该给它们赋予较高的权重，并选来作为该类文本的特征词以区别与其它类文档。

在一份给定的文件里，词频（term frequency，TF）指的是某一个给定的词语在该文件中出现的频率。这个数字是对词数(term count)的归一化，以防止它偏向长的文件。（同一个词语在长文件里可能会比短文件有更高的词数，而不管该词语重要与否。）对于在某一特定文件里的词语 t_{i} 来说，它的重要性可表示为：

​                                                                                 ${tf_{i,j}} = \frac{n_{i,j}}{\sum_k n_{k,j}}$

 以上式子中 n$_{i,j}$ 是该词t${i}$ 在文件d${j}$中的出现次数，而分母则是在文件d${j}$中所有字词的出现次数之和。

逆向文件频率（inverse document frequency，IDF）是一个词语普遍重要性的度量。某一特定词语的IDF，可以由总文件数目除以包含该词语的文件数目，再将得到的商取对数得到：

​                                                                                ${idf_{i}} =  \log \frac{|D|}{|\{j: t_{i} \in d_{j}\}|}$
其中

- |D|：语料库中的文件总数。
- $|\{ j: t_{i} \in d_{j}\}|*$：包含词语t${i}$的文件数目（即 $n_{i,j}\neq0$的文件数目）如果该词语不在语料库中，就会导致被除数为零，因此一般情况下使用1 + $|\{j : t{i} \in d_{j}\}|$

​                                                                               ${tf{}idf_{i,j}} = \mathrm{tf_{i,j}} \times  \mathrm{idf_{i}}$

某一特定文件内的高词语频率，以及该词语在整个文件集合中的低文件频率，可以产生出高权重的TF-IDF。因此，TF-IDF倾向于过滤掉常见的词语，保留重要的词语。

**示例**

根据关键字k1,k2,k3进行搜索结果的相关性就变成TF1IDF1 + TF2IDF2 + TF3IDF3。比如document1的term总量为1000，k1,k2,k3在document1出现的次数是100，200，50。包含了 k1, k2, k3的document总量分别是 1000， 10000，5000。document set的总量为10000。 TF1 = 100/1000 = 0.1 TF2 = 200/1000 = 0.2 TF3 = 50/1000 = 0.05 IDF1 = log(10000/1000) = log(10) = 2.3 IDF2 = log(10000/100000) = log(1) = 0; IDF3 = log(10000/5000) = log(2) = 0.69 这样关键字k1,k2,k3与docuement1的相关性= 0.12.3 + 0.20 + 0.050.69 = 0.2645 其中k1比k3的比重在document1要大，k2的比重是0。



### PageRank && HITS

#### PageRank

PageRank算法的基本思想是：页面的重要程度用PageRank值来衡量，PageRank值主要体现在两个方面：引用该页面的页面个数和引用该页面的页面重要程度。一个页面P（A）被另一个页面P（B）引用，可看成P（B）推荐P（A），P（B）将其重要程度（PageRank值）平均的分配P（B）所引用的所有页面，所以越多页面引用P（A），则越多的页面分配PageRank值给P（A），PageRank值也就越高，P（A）越重要。另外，P(B)越重要，它所引用的页面能分配到的PageRank值就越多，P（A）的PageRank值也就越高，也就越重要。

​         其计算公式为：

​                                                                          ![搜索引擎网页排序算法](http://www.hyqb.sh.cn/Portals/2/2(27).jpg)
​         PR（A）：页面A的PageRank值；

​         d：阻尼系数，由于某些页面没有入链接或者出链接，无法计算PageRank值，为避免这个问题（即LinkSink问题），而提出的。阻尼系数常指定为0.85。

​         R（Pi）：页面Pi的PageRank值；

​         C（Pi）：页面链出的链接数量；



**示例**

有五个页面，链入链出信息如图：

​                                                        ![111](https://github.com/zhangxiaoyidog/photo/blob/master/1.png)

列出矩阵表示并标准化

​                                         ![3](https://github.com/zhangxiaoyidog/photo/blob/master/3.png)

迭代计算

​                                     ![2](https://github.com/zhangxiaoyidog/photo/blob/master/2.png)

#### HITS

HITS（Hyperlink Induced Topic Search）算法是Kleinberg在1998年提出的，是基于超链接分析排序算法中另一个最著名的算法之一。该算法按照超链接的方向，将网页分成两种类型的页面：Authority页面和Hub页面。Authority页面又称权威页面，是指与某个查询关键词和组合最相近的页面，Hub页面又称目录页，该页面的内容主要是大量指向Authority页面的链接，它的主要功能就是把这些Authority页面联合在一起。对于Authority页面P，当指向P的Hub页面越多，质量越高，P的Authority值就越大；而对于Hub页面H，当H指向的Authority的页面越多，Authority页面质量越高，H的Hub值就越大。对整个Web集合而言，Authority和Hub是相互依赖、相互促进，相互加强的关系。Authority和Hub之间相互优化的关系，即为HITS算法的基础。

 HITS基本思想是：算法根据一个网页的入度（指向此网页的超链接）和出度（从此网页指向别的网页）来衡量网页的重要性。在限定范围之后根据网页的出度和入度建立一个矩阵，通过矩阵的迭代运算和定义收敛的阈值不断对两个向量Authority和Hub值进行更新直至收敛。

实验数据表明，HITS的排名准确性要比PageRank高，HITS算法的设计符合网络用户评价网络资源质量的普遍标准，因此能够为用户更好的利用网络信息检索工具访问互联网资源带来便利。

但却存在以下缺陷：首先，HITS算法只计算主特征向量，处理不好主题漂移问题；其次，进行窄主题查询时，可能产生主题泛化问题；第三，HITS算法可以说一种实验性质的尝试。它必须在网络信息检索系统进行面向内容的检索操作之后，基于内容检索的结果页面及其直接相连的页面之间的链接关系进行计算。尽管有人尝试通过算法改进和专门设立链接结构计算服务器（Connectivity Server）等操作，可以实现一定程度的在线实时计算，但其计算代价仍然是不可接受的。

​                                 ![4](https://github.com/zhangxiaoyidog/photo/blob/master/4.png)



























