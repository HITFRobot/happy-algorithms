# 知识蒸馏--Distilling the Knowledge in a neural network

------

对于许多机器学习算法而言，模型的训练和应用所追求的目标是不同的
> * **训练** 需要尽可能多的从训练数据中提取有用的信息，随着深度学习的发展，要求训练的结果尽可能满足目标函数的要求，各种准确率等结果要求的提升，深度学习模型往往更深，更宽，更复杂，这就导致了高额 的运算代价，我们选择的模型更可能是非常复杂，或是数个模型的组合（boosting）。
> * **应用** 的目标则要求花费的时间尽可能少，并且能得到很好的目标。当被用于预测的模型非常复杂时，即参数运算量非常多时，会使预测时间过长，会导致应用中的实时性无法满足；同时高额的运算代价，使得我们训练好的模型无法应用与可移动设备端，会使得移动端硬件成本过高或无法实现。

对于训练和应用的矛盾，Hinton大神用了一个有趣的比喻，许多昆虫有好多个形态，幼年期可能身体肥大，行动能力差，但是便于储存能量；成虫之后则变成方便移动和繁殖的形态。而由一种形态变成另一种形态的过程也就是所谓的“进化”。这种进化的理论对于深度学习来说仍然非常适用，一个很自然的想法就是我们是否可以找到一种方法，使得训练的复杂模型，可以进化，即新的模型既能满足复杂模型带来的准确率，同时参数又足够少，可能部署于移动端。Hinton大神给出了其中一种方式，叫做**蒸馏**，或者理解性的翻译为“萃取”。由昆虫的例子我们可以这样理解神经网络：一个复杂的网络结构模型是若干个单独模型组成的集合，或者是一些很强的约束条件下（比如dropout率很高）训练得到的一个很大的网络模型。一旦复杂网络模型训练完成，我们便可以用另一种训练方法：“蒸馏”，把我们需要配置在应用端的缩小模型从复杂模型中提取出来。

“蒸馏”的难点在于如何缩减网络结构但是把网络中的知识保留下来。知识就是一幅将输入向量导引至输出向量的地图。做复杂网络的训练时，作为训练样本的目标，往往采用one-hot结构。这会导致，类别之间的相互关系丢失。举个例子：
> * 当我们用深度学习做一个（狗，猫，书本）三分类问题时，我们使用的one-hot结构的表达，狗的label为【1，0，0】，猫【0，1，0】，书本【0，0，1】，这种表达方式虽然更能被模型接受，但是他忽略了一个重要的类别间的信息，我们很显然的知道，狗和猫之间的差距要远大于狗和书本的差距。

在训练的过程中目标是将正确答案的概率最大化，但这引入了一个副作用：这种网络为所有错误答案分配了概率，即使这些概率非常小。
> * 接上一个例子，模型训练好以后，拿到一副狗的照片，我们预测的概率可能为【0.85，0.149，0.001】，这种表达方式，会使得书本的概率0.001，在梯度下降算法迭代的过程中，逐渐的丢失，或者影响的非常小。
>
>   > - **为什么要软化？**
>
>   ![](https://pic2.zhimg.com/50/v2-c06c2bf088669764517d5c1c7a66d085_hd.jpg)
>
>   ​

这种概率分布称为**软目标** **(Soft Target)**,很自然的我们会考虑到是否可以增大这个Soft Target的分布值。将复杂模型转化为小模型时需要注意保留模型的泛化能力，利用由复杂模型产生的分类概率作为“软目标”来训练小模型即一种有用的方法。在转化阶段，我们可以用同样的训练集或者是另外的“转化”训练集。当复杂模型是由简单模型复合而成时，我们可以用各自的概率分布的代数或者几何平均数作为“软目标”。当“软目标的”熵值较高时，相对“硬目标”，它每次训练可以提供更多的信息和更小的梯度方差，因此小模型可以用更少的数据和更高的学习率进行训练。

**Knowledge Distill是一种简单弥补分类问题监督信号不足的办法** 



Soft Target:![Soft Target](http://img.blog.csdn.net/20161213211540188?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhvbmdzaGFveXk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

T 越大，softmax的分布越平滑。



## **知识蒸馏算法描述**：

![](https://pic3.zhimg.com/50/v2-271064c09d53934a346cff1fafcc466b_hd.jpg)



> * **框架描述**：
>
>   1、训练大模型：先用hard target，也就是正常的label训练大模型。
>   2、计算soft target：利用训练好的大模型来计算soft target。也就是大模型“软化后”再经过softmax的output。
>   3、训练小模型，在小模型的基础上再加一个额外的soft target的loss function，通过lambda来调节两个loss functions的比重。
>   4、预测时，将训练好的小模型按常规方式（右图）使用。
>
> * YJango链接：https://www.zhihu.com/question/50519680/answer/136406661



##**算法结果展示 **

![img](http://img.blog.csdn.net/20161213211631549?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvemhvbmdzaGFveXk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

![img](http://img.blog.csdn.net/20161213211956251)



## 思考

基于知识蒸馏已经有非常多的应用成果，一个很自然的想法就是，为了节约计算概率我们把模型从复杂变为简单，另一种我们是否一个将复杂的算法变得更复杂：**即我们不考虑计算代价，只是为了提升结果?**

当然这也是可行方案，《RECURRENT NEURAL NETWORK TRAININGWITH DARK KNOWLEDGE TRANSFER》算法即阐述了这个理论。